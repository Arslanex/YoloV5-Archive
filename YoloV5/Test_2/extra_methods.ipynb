{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch Dökümanından Alıntı :: Temel Kullanım"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\enesa/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-11-24 Python-3.10.5 torch-1.12.0 CUDA:0 (NVIDIA GeForce GTX 1650 Ti, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2 as cv\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Image\n",
    "im = cv.imread(\"test_image_1.jpeg\")\n",
    "\n",
    "# Inference\n",
    "results = model(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[         xmin        ymin        xmax        ymax  confidence  class  \\\n 0  284.584351  447.306458  405.060638  531.773926    0.923224      2   \n 1   88.956612  433.869110  286.443634  574.758118    0.922351      2   \n 2  587.734924  444.806091  617.070740  466.548431    0.733097      2   \n 3  402.211823  425.034424  496.011688  506.089020    0.693972      2   \n 4  639.535034  451.793610  667.238342  468.053101    0.632966      2   \n 5  616.621643  452.753204  637.200806  467.346039    0.274041      2   \n 6  654.151855  402.991486  662.913086  416.806396    0.251600      9   \n \n             name  \n 0            car  \n 1            car  \n 2            car  \n 3            car  \n 4            car  \n 5            car  \n 6  traffic light  ]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pandas().xyxy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[       xmin      ymin      xmax      ymax  confidence  class           name\n 0  0.284584  0.670624  0.405061  0.797262    0.923224      2            car\n 1  0.088957  0.650478  0.286444  0.861706    0.922351      2            car\n 2  0.587735  0.666876  0.617071  0.699473    0.733097      2            car\n 3  0.402212  0.637233  0.496012  0.758754    0.693972      2            car\n 4  0.639535  0.677352  0.667238  0.701729    0.632966      2            car\n 5  0.616622  0.678790  0.637201  0.700669    0.274041      2            car\n 6  0.654152  0.604185  0.662913  0.624897    0.251600      9  traffic light]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pandas().xyxyn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result Yapısı"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 667x1000 6 cars, 1 traffic light\n",
      "Speed: 4.0ms pre-process, 97.7ms inference, 3.0ms NMS per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[2.84584e+02, 4.47306e+02, 4.05061e+02, 5.31774e+02, 9.23224e-01, 2.00000e+00],\n",
      "        [8.89566e+01, 4.33869e+02, 2.86444e+02, 5.74758e+02, 9.22351e-01, 2.00000e+00],\n",
      "        [5.87735e+02, 4.44806e+02, 6.17071e+02, 4.66548e+02, 7.33097e-01, 2.00000e+00],\n",
      "        [4.02212e+02, 4.25034e+02, 4.96012e+02, 5.06089e+02, 6.93972e-01, 2.00000e+00],\n",
      "        [6.39535e+02, 4.51794e+02, 6.67238e+02, 4.68053e+02, 6.32966e-01, 2.00000e+00],\n",
      "        [6.16622e+02, 4.52753e+02, 6.37201e+02, 4.67346e+02, 2.74041e-01, 2.00000e+00],\n",
      "        [6.54152e+02, 4.02991e+02, 6.62913e+02, 4.16806e+02, 2.51600e-01, 9.00000e+00]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(results.xyxy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM: 0  //  tensor([284.58435, 447.30646, 405.06064, 531.77393,   0.92322,   2.00000], device='cuda:0')\n",
      "NUM: 1  //  tensor([ 88.95661, 433.86911, 286.44363, 574.75812,   0.92235,   2.00000], device='cuda:0')\n",
      "NUM: 2  //  tensor([587.73492, 444.80609, 617.07074, 466.54843,   0.73310,   2.00000], device='cuda:0')\n",
      "NUM: 3  //  tensor([402.21182, 425.03442, 496.01169, 506.08902,   0.69397,   2.00000], device='cuda:0')\n",
      "NUM: 4  //  tensor([6.39535e+02, 4.51794e+02, 6.67238e+02, 4.68053e+02, 6.32966e-01, 2.00000e+00], device='cuda:0')\n",
      "NUM: 5  //  tensor([6.16622e+02, 4.52753e+02, 6.37201e+02, 4.67346e+02, 2.74041e-01, 2.00000e+00], device='cuda:0')\n",
      "NUM: 6  //  tensor([6.54152e+02, 4.02991e+02, 6.62913e+02, 4.16806e+02, 2.51600e-01, 9.00000e+00], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in results.xyxy:\n",
    "    for num, j in enumerate(i):\n",
    "        print(\"NUM:\",num, \" // \", j)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM: 0  //  tensor([0.28458, 0.67062, 0.40506, 0.79726, 0.92322, 2.00000], device='cuda:0')\n",
      "NUM: 1  //  tensor([0.08896, 0.65048, 0.28644, 0.86171, 0.92235, 2.00000], device='cuda:0')\n",
      "NUM: 2  //  tensor([0.58773, 0.66688, 0.61707, 0.69947, 0.73310, 2.00000], device='cuda:0')\n",
      "NUM: 3  //  tensor([0.40221, 0.63723, 0.49601, 0.75875, 0.69397, 2.00000], device='cuda:0')\n",
      "NUM: 4  //  tensor([0.63954, 0.67735, 0.66724, 0.70173, 0.63297, 2.00000], device='cuda:0')\n",
      "NUM: 5  //  tensor([0.61662, 0.67879, 0.63720, 0.70067, 0.27404, 2.00000], device='cuda:0')\n",
      "NUM: 6  //  tensor([0.65415, 0.60419, 0.66291, 0.62490, 0.25160, 9.00000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in results.xyxyn:\n",
    "    for num, j in enumerate(i):\n",
    "        print(\"NUM:\",num, \" // \", j)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "print(len(results.xyxyn))\n",
    "print(len(results.xyxyn[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.28458, 0.67062, 0.40506, 0.79726, 0.92322, 2.00000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(results.xyxyn[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(results.xyxyn[0][0, -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(results.xyxyn[0][0][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.28458, 0.67062, 0.40506, 0.79726, 0.92322, 2.00000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(results.xyxyn[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.28458, 0.67062, 0.40506, 0.79726, 0.92322], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(results.xyxyn[0][0, :-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.28458, 0.67062, 0.40506, 0.79726, 0.92322], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(results.xyxyn[0][0][:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Yüklerken Parametreler ve Kendi Modelini Yükleme"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', device=\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', _verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', channels=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=\"yolov5/custom.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Threadler ile 2 Modelin Eş Zamanlı Çalışması"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import threading\n",
    "\n",
    "def run(model, im):\n",
    "  results = model(im)\n",
    "  results.save()\n",
    "\n",
    "# Models\n",
    "model0 = torch.hub.load('ultralytics/yolov5', 'yolov5s', device=0)\n",
    "model1 = torch.hub.load('ultralytics/yolov5', 'yolov5s', device=1)\n",
    "\n",
    "# Inference\n",
    "threading.Thread(target=run, args=[model0, 'test_image_1.jpeg'], daemon=True).start()\n",
    "threading.Thread(target=run, args=[model1, 'test_image_2.jpeg'], daemon=True).start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}